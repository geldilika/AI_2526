{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248444eb-6c97-4c61-aa2e-20c5005c7985",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f00e97746da8063f990e935ff0795489",
     "grade": false,
     "grade_id": "cell-ed26fe424247e7e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# COM2028 Coursework 25/26\n",
    "\n",
    "**Topics:**  \n",
    "1. Linear algebra (under/overdetermined systems)  \n",
    "2. Probability\n",
    "3. Linear regression  \n",
    "4. Logistic regression\n",
    "5. Unsupervised learning – K-means clustering \n",
    "6. Classification – Convolutional Neural Networks (PyTorch)\n",
    "\n",
    "**Instructions**\n",
    "- Implement code only in **solution** cells marked with `# YOUR CODE HERE` and `raise NotImplementedError()`.\n",
    "- Do not change function signatures or make modifications on locked cells.\n",
    "- **DO NOT ERASE OR CREATE CELLS**.\n",
    "- All datasets are generated **inside the notebook**.\n",
    "- The autograder will re-generate **hidden datasets** with different seeds/parameters to prevent hardcoding.\n",
    "- **Public tests** are visible.\n",
    "- **Hidden tests** will run on different seeds, parameters, and augmentation.\n",
    "- **Do not** import extra libraries other than those already imported.\n",
    "- **Do not** load or save external files—everything must run in this notebook.\n",
    "- **Reproducibility:** Use provided RNG helpers.\n",
    "- **Do not** set global seeds in your solutions.\n",
    "\n",
    "**Academic integrity:** The design includes randomized hidden tests, gradient checks, and banned import checks to detect shortcuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58658a01-01b5-4f42-aaa5-7353fab0f3f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c396f31d861c9580139672da447965d",
     "grade": false,
     "grade_id": "cell-9de4d756cb0a3231",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.19' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY: Imports, utilities, and global configuration\n",
    "import math, sys, os, inspect\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Callable, Dict, Any\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "# Lightweight banned token checks on student's function source (not bulletproof).\n",
    "BANNED_TOKENS = {\n",
    "    'global': ['sklearn', 'tensorflow', 'keras', 'scikit-image'],\n",
    "    'q1': ['np.linalg.pinv', 'np.linalg.lstsq', 'scipy.linalg.lstsq', 'scipy.linalg.pinv', 'np.linalg.svd', 'np.linalg.solve']\n",
    "}\n",
    "\n",
    "def _check_banned(func, scope='global'):\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "    except Exception:\n",
    "        return  # If source can't be retrieved (rare), skip\n",
    "    toks = BANNED_TOKENS.get(scope, []) + BANNED_TOKENS['global']\n",
    "    for t in toks:\n",
    "        if t in src:\n",
    "            raise AssertionError(f\"Use of banned token '{t}' detected in {func.__name__}.\")\n",
    "\n",
    "# Test helpers\n",
    "def rel_error(x, y, eps=1e-12):\n",
    "    num = np.linalg.norm(x - y)\n",
    "    den = np.linalg.norm(x) + np.linalg.norm(y) + eps\n",
    "    return num / den\n",
    "\n",
    "def numeric_grad(f: Callable[[np.ndarray], float], x: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    grad = np.zeros_like(x)\n",
    "    for i in range(x.size):\n",
    "        old = x.flat[i]\n",
    "        x.flat[i] = old + eps\n",
    "        f1 = f(x)\n",
    "        x.flat[i] = old - eps\n",
    "        f2 = f(x)\n",
    "        x.flat[i] = old\n",
    "        grad.flat[i] = (f1 - f2) / (2 * eps)\n",
    "    return grad\n",
    "\n",
    "# RNG helper to avoid students overriding global state\n",
    "@dataclass\n",
    "class RNG:\n",
    "    seed: int\n",
    "    def rand(self, *shape):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        return rng.random(shape)\n",
    "    def normal(self, *shape, mean=0.0, std=1.0):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        return rng.normal(mean, std, size=shape)\n",
    "    def integers(self, low, high=None, size=None):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        return rng.integers(low, high, size=size)\n",
    "    def choice(self, a, size=None, replace=True):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        return rng.choice(a, size=size, replace=replace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be25b6-32e8-4665-b05a-e6618954185e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ab7ca9410ee32af2c912d87d7c7314b",
     "grade": false,
     "grade_id": "cell-f82bc151f51e7265",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1. Linear algebra: under-/overdetermined solutions of system of equations (20 marks)\n",
    "\n",
    "**Task: Implement**\n",
    "\n",
    "- Underdetermined (m < n) solution to system of equations $\\mathbf{A x} = \\mathbf{y}$.\n",
    "- Overdetermined (m > n) solution to system of equations $\\mathbf{A x} \\approx \\mathbf{y}$.\n",
    "  \n",
    "**Restriction (Q1): You cannot use direct solvers np.linalg.pinv, np.linalg.lstsq, np.linalg.solve, np.linalg.svd.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b77a6-0a47-41a8-94dc-65dca0472ec5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4edfca8ce3e29c9ef9439f37c1056277",
     "grade": false,
     "grade_id": "cell-ba590de881bd5a58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY: Q1 data generators\n",
    "\n",
    "def gen_underdetermined(m=10, n=15, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    A = rng.normal(size=(m, n))\n",
    "    x_true = rng.normal(size=(n,))\n",
    "    y = A @ x_true  # exact\n",
    "    return A, y, x_true\n",
    "\n",
    "def gen_overdetermined(m=80, n=5, noise=0.1, seed=1):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    A = rng.normal(size=(m, n))\n",
    "    x_true = rng.normal(size=(n,))\n",
    "    y = A @ x_true + rng.normal(scale=noise, size=(m,))\n",
    "    return A, y, x_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73f691-98ba-4aef-ad55-ac96bc9d7821",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82063845d86f1a4261bbc05ad54a27f1",
     "grade": false,
     "grade_id": "cell-d8676f4842113b27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1.1 Implement underdetermined(A, y) returning solution x that satisfies $\\mathbf{A x} = \\mathbf{y}$ ($m<n$) (10 marks)\n",
    "\n",
    "**Hint: Look at solution from the lecture slides, but DO NOT call direct solvers np.linalg.pinv, np.linalg.lstsq, np.linalg.svd, np.linalg.solve directly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41901b-8896-43a0-ab80-42f13512cff5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2bcf72f6b39907d4aa0a77111ea2642",
     "grade": false,
     "grade_id": "cell-3a27530abb0cffa3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def underdetermined(A: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return solution to A x = y for m < n.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : (m, n) np.ndarray\n",
    "    y : (m,) np.ndarray\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : (n,) np.ndarray\n",
    "        The unique minimum-norm solution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    G = A @ A.T\n",
    "    w = np.linalg.inv(G) @ y\n",
    "    \n",
    "    x = (A.T @ w)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767710f-befc-454f-8b3f-d3c7459f8bc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0df0011bb58084ed7c430e2e3bee6bbf",
     "grade": true,
     "grade_id": "cell-371e0c9c57036edd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q1.1 Public Tests (2 marks)\n",
    "\n",
    "A, y, _ = gen_underdetermined(8, 12, 42)\n",
    "\n",
    "def ref_min_norm(A, y):\n",
    "    U, s, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "    s_inv = np.array([1/si if si>1e-12 else 0.0 for si in s])\n",
    "    return Vt.T @ np.diag(s_inv) @ U.T @ y\n",
    "\n",
    "x = underdetermined(A, y)\n",
    "_check_banned(underdetermined, scope='q1')\n",
    "ref = ref_min_norm(A, y)\n",
    "assert x.shape == (12,)\n",
    "assert rel_error(x, ref) < 1e-7\n",
    "print(\"Passed tests: +2 marks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186225a-e75e-4047-b43d-db2868e23800",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e33dac9c4e82e597f234857a25a09462",
     "grade": true,
     "grade_id": "cell-8f1e221f015abda8",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q1.1 Hidden Tests (4 marks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660504f5-f0db-4196-9182-1d9c2190e874",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93715517ecaba093f757a503bfa99c2b",
     "grade": true,
     "grade_id": "cell-d1ff01c77e681743",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q1.1 Hidden Tests (4 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc6753-f965-4e56-9269-0c8936524b3f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c150cbac885dfaaa9d4562d805422817",
     "grade": false,
     "grade_id": "cell-5d657af9b8fdb0a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1.2 Implement overdetermined(A, y) returning solution x that satisfies $\\mathbf{A x} \\approx \\mathbf{y}$  ($m>n$) (10 marks).\n",
    "\n",
    "**Hint: Look at solution from the lecture slides, but DO NOT call direct solvers np.linalg.pinv, np.linalg.lstsq, np.linalg.svd, np.linalg.solve directly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d049d5-5af0-42ef-a6ba-39018df8c5a3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4b42a75426ad8b6739d10395ad0fef9",
     "grade": false,
     "grade_id": "cell-c52ef0f4307fe8a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def overdetermined(A: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return solution to A x = y for m > n.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : (m, n) np.ndarray\n",
    "    y : (m,) np.ndarray\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : (n,) np.ndarray\n",
    "        The unique minimum-norm solution.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    G = A.T @ A\n",
    "    b = A.T @ y\n",
    "    \n",
    "    x = (np.linalg.inv(G) @ b)\n",
    "    \n",
    "    return x\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0bba9-0192-4e47-a465-95566ca875ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d2ae9f6fdc76f76669a1621531b35a4",
     "grade": true,
     "grade_id": "cell-056ea909b0ca5759",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q1.2 Public Tests (2 marks)\n",
    "A, y, _ = gen_overdetermined(120, 6, 0.05, 7)\n",
    "x = overdetermined(A, y)\n",
    "_check_banned(overdetermined, scope='q1')\n",
    "ATA = A.T @ A + 1e-4*np.eye(6)\n",
    "ATy = A.T @ y\n",
    "ref = np.linalg.solve(ATA, ATy)\n",
    "assert rel_error(x, ref) < 1e-3\n",
    "print(\"Passed tests: +2 marks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e9680-9225-43db-9ba0-f364ed0c7874",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74573fa2c764003c73ad9eedc26c7938",
     "grade": true,
     "grade_id": "cell-1c61231bc2754301",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q1.2 Hidden Tests (4 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da29e5-ef9f-4e34-a78b-4a7d8909ba1f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80b9df9ae56701e62474f3ddf5d5e90e",
     "grade": true,
     "grade_id": "cell-13f743045a61a575",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q1.2 Hidden Tests (4 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e547195-3a2c-416f-a4cb-9f0e63818370",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "803bd397541ac3a150d1c27d66242aa3",
     "grade": false,
     "grade_id": "cell-52d2f3353a8da5f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2. Probability: Conditional Probability and Bayes' Theorem (5 marks)\n",
    "\n",
    "A factory has two machines, **M1** and **M2**, producing widgets:\n",
    "- Machine M1 produces P(M1) of all widgets, and Machine M2 produces P(M2).\n",
    "- M1 produces defective widgets P(defective | M1) of the time, while M2 produces defective widgets P(defective | M2) of the time.\n",
    "\n",
    "We pick a widget at random and observe that it is defective.\n",
    "\n",
    "**Task:**\n",
    "2. Write a function `bayes_defective(p_m1, p_m2, p_def_m1, p_def_m2)` that returns the probability that the defective widget came from Machine M1 given:\n",
    "   - `p_m1`: prior probability of M1\n",
    "   - `p_m2`: prior probability of M2\n",
    "   - `p_def_m1`: P(defective | M1)\n",
    "   - `p_def_m2`: P(defective | M2)\n",
    "\n",
    "**Hint:**  \n",
    "$$\n",
    "P(M_1 \\mid D) = \\frac{P(D \\mid M_1) P(M_1)}{P(D \\mid M_1) P(M_1) + P(D \\mid M_2) P(M_2)}\n",
    "$$\n",
    "\n",
    "**Restriction (Q2): Do not import/call sklearn, tensorflow, keras, scikit-image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac3cd3-34d5-4d89-9253-a8b7a817ad31",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1f04878fb545de6570b432890b4ba48",
     "grade": false,
     "grade_id": "cell-a94883c6a23c6e83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def bayes_defective(p_m1: float, p_m2: float, p_def_m1: float, p_def_m2: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the posterior probability that a defective item came from machine 1\n",
    "    using Bayes' theorem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_m1 : float\n",
    "        Prior probability that an item is produced by machine 1.\n",
    "    p_m2 : float\n",
    "        Prior probability that an item is produced by machine 2.\n",
    "    p_def_m1 : float\n",
    "        Probability that an item is defective given it was produced by machine 1.\n",
    "    p_def_m2 : float\n",
    "        Probability that an item is defective given it was produced by machine 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Posterior probability that a defective item was produced by machine 1.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24723ac0-f361-4041-a401-cda80e498603",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22348af27ec02bcff4cabf99bced2d3f",
     "grade": true,
     "grade_id": "cell-cb8c8e051565f6fe",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q2 Public Tests (1 mark)\n",
    "_check_banned(bayes_defective)\n",
    "p = bayes_defective(0.6, 0.4, 0.01, 0.02)\n",
    "assert abs(p - 0.42857) < 1e-4, f\"Expected ~0.42857, got {p}\"\n",
    "print(\"Passed tests: +1 mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392a80f-edcb-441e-98b4-113c79319f13",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b04845a9cc0787af3ed1e6d7494ffa02",
     "grade": true,
     "grade_id": "cell-04854979868caf29",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q2 Hidden Tests (4 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876f5a8-1478-4dfe-878c-e017172196e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6bfe893d9697c391090128620e5dbd74",
     "grade": false,
     "grade_id": "cell-3a69ff59c306b0b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q3. Linear regression (20 marks)\n",
    "\n",
    "- We provide code to generate synthetic data for the linear regression problem\n",
    "\n",
    "**Task: implement**\n",
    "- closed-form ridge and\n",
    "- gradient descent (using both full-batch or mini-batch).\n",
    "\n",
    "**Restriction (Q3): Do not import/call sklearn, tensorflow, keras, scikit-image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84fa40-a0ca-4df6-a2f0-8713577f71e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44dca4b61b1070c4e7a7a7b327912c26",
     "grade": false,
     "grade_id": "cell-ba9b8448e8203ef5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY: Q3 data generator\n",
    "def gen_linreg(n_samples=500, n_features=10, noise=0.5, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = rng.normal(size=(n_samples, n_features))\n",
    "    w_true = rng.normal(size=(n_features,))\n",
    "    y = X @ w_true + rng.normal(scale=noise, size=(n_samples,))\n",
    "    return X, y, w_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c90ab0-74a3-40c5-8d4b-ec088b853d4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ec54d4b15c5d4dea07bdc304c03a95d",
     "grade": false,
     "grade_id": "cell-05a4363353bb9ba8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3.1 — Closed-form ridge regression (10 marks)\n",
    "\n",
    "**Task.** Implement closed-form ridge regression.  \n",
    "You should write a function that takes a matrix `X` (shape `n x d`), targets `y` (`n`), and a regularization strength `reg` (≥ 0), and returns the fitted weight vector `w` (shape `d`). \n",
    "\n",
    "**Notes / requirements**\n",
    "- Use the standard closed-form solution:\n",
    "  $$\\mathbf{w} = (\\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I})^{-1}\\mathbf{X}^\\top \\mathbf{y},$$\n",
    "\n",
    "Implement the function in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e877ae-2f55-481c-a51c-1f8abb22623f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25cf538639d7c004399c650845753450",
     "grade": false,
     "grade_id": "cell-299d5763189a7fb9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ridge_closed_form(X: np.ndarray, y: np.ndarray, reg: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Closed form ridge regression\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : (n, d) design matrix\n",
    "    y : (n,) target vector\n",
    "    reg : L2 regularization strength (lambda)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : (d,) learned weights\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca5d4d-c6ca-40bd-baf6-a1c682d6abf3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26e121d77a630d19910d228b56ae91a2",
     "grade": true,
     "grade_id": "cell-db143eaf79f47673",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q3.1 Public Tests (2 marks)\n",
    "X, y, _ = gen_linreg(800, 12, 0.1, 10)\n",
    "w_cf = ridge_closed_form(X, y, reg=1e-3)\n",
    "_check_banned(ridge_closed_form)\n",
    "ref = np.linalg.solve(X.T @ X + 1e-3*np.eye(X.shape[1]), X.T @ y)\n",
    "assert w_cf.shape == (X.shape[1],)\n",
    "assert rel_error(w_cf, ref) < 1e-7\n",
    "print(\"Passed tests: +2 marks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e466c08-2f99-4fec-b043-b62bd7f5d310",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76861d8f0159ede0c46dd17dee251f00",
     "grade": true,
     "grade_id": "cell-c623df1532a1f1ac",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q3.1 Hidden Tests (4 marks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d842251-9d51-4b0b-8cd1-19429b6276f6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94523c269ef0808516b3086053969317",
     "grade": true,
     "grade_id": "cell-92db889b093932fd",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q3.1 Hidden Tests (4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86afa593-678e-4fa9-818c-398065b7c2ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a588d505f15b204522600a2a843f841",
     "grade": false,
     "grade_id": "cell-969fbea00d7660f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3.2 — Gradient Descent Regression (10 marks)\n",
    "\n",
    "**Task.** In this question, you will implement linear regression trained by gradient descent, with support for **optional L2 regularization (ridge regression)**.  \n",
    "Unlike Q3.1, which relied on the closed-form solution, here you will explicitly optimize the loss function using iterative updates.\n",
    "\n",
    "**Requirements**\n",
    "- Implement a function that fits a linear regression model to data `X, y` using **full-batch gradient descent (GD)** or **mini-batch stochastic gradient descent (SGD)**.  \n",
    "- The objective function is:\n",
    "  $$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{2n}\\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|^2_2 + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|^2_2,$$\n",
    "  where \\(\\lambda \\geq 0\\) controls the strength of L2 regularization (set \\(\\lambda = 0\\) for plain linear regression).\n",
    "- In this function, the gradient is defined by\n",
    "  $$\\nabla_w \\mathcal{L}(\\mathbf{w}) = \\frac{1}{n}\\mathbf{X}^{\\top}(\\mathbf{X}\\mathbf{w}-\\mathbf{y})+\\lambda\\mathbf{w},$$\n",
    "  and the update rule for GD and SGD is\n",
    "  $$\\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\nabla_w \\mathcal{L}(\\mathbf{w}),$$ where $\\eta$ is the learning rate.\n",
    "- Your implementation should:\n",
    "  - Accept hyperparameters such as learning rate, number of epochs, batch size, and regularization strength.\n",
    "  - Return both the learned weights and the training loss history.\n",
    "  - Work for full-batch GD, or mini-batch SGD regimes (depending on batch size).\n",
    "\n",
    "**Hints**\n",
    "- Vectorize your gradient computations; avoid explicit Python loops over samples.\n",
    "- Test your implementation on small synthetic data to ensure that the loss decreases over iterations and that the solution approaches the closed-form result from Q3.1 when using full-batch gradient descent with a small learning rate and many iterations.\n",
    "\n",
    "**Restriction (Q3): Do not import/call sklearn, tensorflow, keras, scikit-image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d8dd5-be14-4766-a525-eacd507aedfd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb5ab3bcb6cfb2c3b140ee388f870679",
     "grade": false,
     "grade_id": "cell-da900a37892bc27f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def linreg_gd(X: np.ndarray, y: np.ndarray, lr: float = 0.1, reg: float = 0.0,\n",
    "              epochs: int = 200, batch_size: int | None = None,\n",
    "              w0: np.ndarray | None = None, seed: int = 0) -> Tuple[np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Linear regression with optional L2 regularization via gradient descent / mini-batch SGD.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : (n, d) design matrix\n",
    "    y : (n,) target vector\n",
    "    lr : learning rate\n",
    "    reg : L2 regularization strength (lambda)\n",
    "    epochs : number of passes over the training set\n",
    "    batch_size : if None, use full-batch GD; else mini-batch SGD with given batch size\n",
    "    w0 : optional initial weights (d,)\n",
    "    seed : RNG seed for batch shuffling\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : (d,) learned weights\n",
    "    history : dict with key 'loss' containing per-epoch full-data loss values\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df51344-b1c7-4531-b70b-2b5f0beebe92",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "616b4803fcb7de2b17e85332f31d4020",
     "grade": true,
     "grade_id": "cell-dde483830c5e29d7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q3.2 Public Tests (2 marks)\n",
    "_check_banned(linreg_gd)\n",
    "X, y, _ = gen_linreg(20, 9, 0.3, 10)\n",
    "w_gd, hist = linreg_gd(X, y, lr=0.2, reg=1e-3, epochs=200, batch_size=None, seed=0)\n",
    "w_cf = ridge_closed_form(X, y, reg=1e-2)\n",
    "assert 'loss' in hist and len(hist['loss']) >= 50\n",
    "assert rel_error(w_gd, w_cf) < 1e-2\n",
    "print(\"Passed tests: +2 marks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70d279-6e24-497f-b159-5fdf5a0f8d7b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b270bd09025186153d9811f979ca66",
     "grade": true,
     "grade_id": "cell-9356cc683fa0a0cf",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q3.2 Hidden Tests (4 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d510528-7d4a-4283-8807-032eda9abd26",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a263c9e988192ef4955f16131b083038",
     "grade": true,
     "grade_id": "cell-64ccd5151eeb0348",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q3.2 Hidden Tests (4 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794faa1-d009-4d1c-b59a-6ed34840cd48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a79976dea584b3ae5401359acc9ac4b",
     "grade": false,
     "grade_id": "cell-9a335edc83d8390b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4. Logistic regression (25 marks)\n",
    "\n",
    "In this question, you will implement logistic regression from scratch, including all the core components needed for binary classification:\n",
    "- The sigmoid function to map linear scores to probabilities.\n",
    "- The logistic loss function (cross-entropy) with L2 regularization for weight decay.\n",
    "- The gradient of the loss with respect to model parameters.\n",
    "- A training loop that uses gradient descent to optimize the weights.\n",
    "\n",
    "You will also perform numerical gradient checks to validate your implementation and ensure correctness.\n",
    "\n",
    "**Important restrictions**:\n",
    "- **Restriction (Q4): Do not import/call sklearn, tensorflow, keras, scikit-image, or any pre-built logistic regression functions.**\n",
    "- You may use NumPy for vectorized operations.\n",
    "- Your implementation should be efficient and handle reasonably sized datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4ff9e-04e5-4786-8fe6-9e150eb87bea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d980715cbd023126b72a0a3cae25d25c",
     "grade": false,
     "grade_id": "cell-102efec50a33b761",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY: Q4 data generator\n",
    "def gen_logreg(n_pos=400, n_neg=400, dim=3, separation=1.5, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mu_pos = rng.normal(scale=separation, size=(dim,))\n",
    "    mu_neg = -mu_pos\n",
    "    cov = np.eye(dim)\n",
    "    X_pos = rng.multivariate_normal(mu_pos, cov, size=n_pos)\n",
    "    X_neg = rng.multivariate_normal(mu_neg, cov, size=n_neg)\n",
    "    X = np.vstack([X_pos, X_neg])\n",
    "    y = np.concatenate([np.ones(n_pos), np.zeros(n_neg)])\n",
    "    idx = rng.permutation(X.shape[0])\n",
    "    return X[idx], y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95313ad5-48a6-442a-8bcd-931149615219",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1391d23d85c0015f6f5ab35b322af848",
     "grade": false,
     "grade_id": "cell-02d4c9c13ed8430a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.1 Implementation of the sigmoid function (2 marks)\n",
    "\n",
    "The sigmoid function is a key building block in logistic regression and many neural network models. It maps any real-valued input $\\mathbf{z}$ to a value in the range $(0,1)$, making it suitable for representing probabilities:\n",
    "$$ \\sigma(\\mathbf{z}) = \\frac{1}{1 + \\exp(-\\mathbf{z})}$$\n",
    "Your task is to implement the sigmoid function in a numerically stable way.\n",
    "\n",
    "Why is this important? For large positive or negative values of $\\mathbf{z}$, the naive implementation can cause overflow or underflow in the exponential calculation. For example:\n",
    "- If $\\mathbf{z}$ is very large (e.g., 1000), $e^{-\\mathbf{z}}$ underflows to 0.\n",
    "- If $\\mathbf{z}$ is very negative (e.g., -1000), $e^{-\\mathbf{z}}$ overflows to infinity.\n",
    "\n",
    "To avoid these issues, you should:\n",
    "- Use conditional logic or algebraic tricks to keep values in a safe range.\n",
    "- Ensure the function works for scalars and NumPy arrays.\n",
    "\n",
    "Expected behavior:\n",
    "- Input: NumPy array of any shape.\n",
    "- Output: same shape, with values in $(0,1)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c936f7-37ea-431f-b794-32419f34efee",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da3c22a5cf4133abfbe4758f6bdfe988",
     "grade": false,
     "grade_id": "cell-5ee005a09d393bae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the sigmoid function σ(z) = 1 / (1 + exp(-z)) in a numerically stable way.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : np.ndarray\n",
    "        Input array (can be scalar, vector, or matrix).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Element-wise sigmoid values in the range (0, 1).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3e947-aef9-4cbc-81de-a9832ac0da83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4375b6253de61e0765d5d5d1bb9c578e",
     "grade": true,
     "grade_id": "cell-53b99d5ec8bcbd6b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q4.1 Public Tests (2 marks)\n",
    "_check_banned(sigmoid)\n",
    "X, y = gen_logreg(300, 300, 4, 2.0, 2)\n",
    "z = np.array([-100.0, -1.0, 0.0, 1.0, 100.0])\n",
    "s = sigmoid(z)\n",
    "assert np.all(s >= 0) and np.all(s <= 1)\n",
    "assert np.isclose(s[2], 0.5, atol=1e-8)\n",
    "print(\"Passed tests: +2 marks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80c313-ea93-44a6-a28b-074c6b82a87b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93f18f88f213ffc35a880ea0db17135b",
     "grade": false,
     "grade_id": "cell-fa2f38dbf736f05d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.2: Logistic Loss with L2 Regularization and Gradient (12 marks)\n",
    "\n",
    "In this part, you will implement the **binary logistic regression loss** (average cross-entropy) with **L2 regularization** and its **gradient** with respect to the model parameters.\n",
    "\n",
    "#### Model and Notation\n",
    "Given a dataset of $n$ examples with features $\\mathbf{x}_i \\in \\mathbb{R}^d$ and labels $\\mathbf{y}_i \\in \\{0,1\\}$, the logistic regression model predicts:\n",
    "$$\n",
    "\\mathbf{z}_i = \\mathbf{w}^\\top \\mathbf{x}_i, \\qquad \\hat{\\mathbf{y}}_i = \\sigma(\\mathbf{z}_i) = \\frac{1}{1 + e^{-\\mathbf{z}_i}}.\n",
    "$$\n",
    "\n",
    "#### Loss (average negative log-likelihood)\n",
    "The **average logistic loss** with **L2 regularization** is:\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{w}) = -\\frac{1}{n}\\sum_{i=1}^{n}\\Big[\\mathbf{y}_i \\log \\hat{\\mathbf{y}}_i + (1-\\mathbf{y}_i)\\log(1-\\hat{\\mathbf{y}}_i)\\Big] \\;+\\; \\frac{\\lambda}{2}\\,\\lVert \\mathbf{w} \\rVert_2^2.\n",
    "$$\n",
    "\n",
    "A numerically **stable** and equivalent expression (recommended for implementation) is:\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{w}) \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n}\\Big(\\operatorname{softplus}(\\mathbf{z}_i) - \\mathbf{y}_i \\mathbf{z}_i\\Big) \\;+\\; \\frac{\\lambda}{2}\\,\\lVert \\mathbf{w} \\rVert_2^2,\n",
    "$$\n",
    "where $\\operatorname{softplus}(\\mathbf{z}) = \\log\\big(1 + e^{\\mathbf{z}}\\big)$. \n",
    "\n",
    "#### Gradients\n",
    "Let $ \\hat{\\mathbf{y}} = \\sigma(\\mathbf{z}) $. The gradients of the loss are:\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} \\mathcal{L} \\;=\\; \\frac{1}{n} \\mathbf{X}^\\top (\\hat{\\mathbf{y}} - \\mathbf{y}) \\;+\\; \\lambda \\mathbf{w}.\n",
    "$$\n",
    "\n",
    "#### Requirements & I/O\n",
    "- Inputs:\n",
    "  - `X`: shape `(n, d)` — feature matrix (NumPy array).\n",
    "  - `y`: shape `(n,)` with values in `{0, 1}` — labels.\n",
    "  - `w`: shape `(d,)` — weight vector.\n",
    "  - `lambda` (or `l2`): non-negative scalar — L2 strength.\n",
    "- Outputs:\n",
    "  - `loss`: scalar float — the average regularized loss.\n",
    "  - `grad_w`: shape `(d,)` — gradient w.r.t. `w`.\n",
    "\n",
    "#### Numerical Stability Tips\n",
    "- If you compute via probabilities, clip with a small epsilon (e.g., `p = np.clip(p, 1e-12, 1-1e-12)`) before taking logs to avoid `log(0)`.\n",
    "- Vectorize computations; avoid Python loops for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c623e-0280-4a0a-b217-7fbefa572c39",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b324043b9de8f4e9edc7ceca91966d75",
     "grade": false,
     "grade_id": "cell-ebb7506c8d5889b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def logreg_loss_grad(w: np.ndarray, X: np.ndarray, y: np.ndarray, reg: float = 0.0) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the binary logistic regression average loss with L2 regularization and its gradient.\n",
    "\n",
    "    Loss:\n",
    "        L(w) = (1/n) * sum_i [ softplus(z_i) - y_i * z_i ] + reg * ||w||^2\n",
    "        where z = X @ w, softplus(t) = log(1 + exp(t)) computed stably.\n",
    "\n",
    "    Gradient:\n",
    "        ∇L(w) = (1/n) * X^T (σ(z) - y) + 2 * reg * w\n",
    "        where σ(z) = 1 / (1 + exp(-z)) computed stably.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : (d,) array\n",
    "        Parameter vector.\n",
    "    X : (n, d) array\n",
    "        Design matrix.\n",
    "    y : (n,) array with values in {0,1}\n",
    "        Binary targets.\n",
    "    reg : float >= 0\n",
    "        L2 regularization strength.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "        The average regularized logistic loss.\n",
    "    grad : (d,) array\n",
    "        The gradient of the loss w.r.t. w.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ddb257-0689-4303-85a4-afea64f32e67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "385aefe24d6897aff1651774656753e8",
     "grade": true,
     "grade_id": "cell-8a8cd3b22fcd35eb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q4.2 Public Tests (2 marks)\n",
    "_check_banned(logreg_loss_grad)\n",
    "X, y = gen_logreg(200, 200, 5, 1.3, 10)\n",
    "w = np.zeros(X.shape[1])\n",
    "loss, grad = logreg_loss_grad(w, X, y, reg=1e-3)\n",
    "assert np.isfinite(loss) and np.all(np.isfinite(grad))\n",
    "ng = numeric_grad(lambda ww: logreg_loss_grad(ww, X, y, reg=1e-3)[0], w.copy())\n",
    "assert rel_error(grad, ng) < 1e-5\n",
    "print(\"Passed tests: +2 marks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdad48-6c98-46a7-a867-a70ab069583f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b9225d821833f593a46463101ab69a0",
     "grade": true,
     "grade_id": "cell-41d1fd03d3793191",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q4.2 Hidden Tests (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb5baa-bd8b-4901-8c3e-4c5535a11ea2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31b4932dfb557f1b628d2f1b896d5592",
     "grade": true,
     "grade_id": "cell-147aef07f97c715d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q4.2 Hidden Tests (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd168c-d1ba-4514-a4c5-49245b9a2407",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c124d4ee11c45b3970463bda2bd661c3",
     "grade": false,
     "grade_id": "cell-389e6c41cba4c052",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.3: Training a Logistic Regression Model (11 marks)\n",
    "\n",
    "In this part, you will implement a **gradient descent training loop** for binary logistic regression using the stable loss and gradient function you wrote in the previous question (`logreg_loss_grad`).\n",
    "\n",
    "#### **What you need to do**\n",
    "- Initialize the model parameters:\n",
    "  - `w`: weight vector of shape `(d,)` (e.g., zeros or small random values).\n",
    "- For a given number of epochs:\n",
    "  1. Compute the **loss** and **gradients** using your `logreg_loss_grad` function.\n",
    "  2. Update the parameters using **gradient descent**:\n",
    "     $$\n",
    "     \\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\cdot \\nabla_{\\mathbf{w}}\n",
    "     $$\n",
    "     where $\\eta$ is the learning rate.\n",
    "  3. Record the **full-dataset loss** at each epoch for monitoring convergence.\n",
    "\n",
    "#### **Inputs**\n",
    "- `X`: shape `(n, d)` — feature matrix.\n",
    "- `y`: shape `(n,)` — binary labels in `{0,1}`.\n",
    "- `epochs`: number of passes over the dataset.\n",
    "- `lr`: learning rate.\n",
    "- `reg`: L2 regularization strength.\n",
    "\n",
    "#### **Outputs**\n",
    "- `w`: learned weight vector of shape `(d,)`.\n",
    "- `history`: dictionary with:\n",
    "  - `loss`: list of per-epoch loss values (full dataset).\n",
    "\n",
    "#### **Requirements**\n",
    "- Use **full-batch gradient descent** (compute loss and gradient on the entire dataset each epoch).\n",
    "- Do **not** use scikit-learn or any external ML library.\n",
    "- Ensure your implementation is **vectorized** for efficiency.\n",
    "\n",
    "#### **Hints**\n",
    "- Start with a small learning rate and check if the loss decreases.\n",
    "- Use your previous implementation of `logreg_loss_grad` for stability.\n",
    "- You can print or plot the loss curve to verify convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268d3de-940d-4c2b-9e71-efcd9af27a70",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "098694f3b422d4f2da141336e44acf1b",
     "grade": false,
     "grade_id": "cell-2bbc91b72fdf8eeb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_logreg(X: np.ndarray,\n",
    "                 y: np.ndarray,\n",
    "                 lr: float = 0.1,\n",
    "                 reg: float = 0.0,\n",
    "                 epochs: int = 200,\n",
    "                 w0: np.ndarray | None = None) -> Tuple[np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Train binary logistic regression with L2 regularization via (full-batch) gradient descent.\n",
    "\n",
    "    Minimizes (average) loss:\n",
    "        L(w) = (1/n) * sum_i [ softplus(z_i) - y_i * z_i ] + reg * ||w||^2\n",
    "        where z = X @ w and softplus(t) = log(1 + exp(t)) computed stably in logreg_loss_grad.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : (n, d) ndarray\n",
    "        Design matrix.\n",
    "    y : (n,) ndarray of {0,1}\n",
    "        Binary labels.\n",
    "    lr : float\n",
    "        Learning rate (step size).\n",
    "    reg : float >= 0\n",
    "        L2 regularization strength (lambda).\n",
    "    epochs : int\n",
    "        Number of passes over the dataset.\n",
    "    w0 : (d,) ndarray or None\n",
    "        Optional initialization; if None, initializes to zeros.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : (d,) ndarray\n",
    "        Learned parameter vector.\n",
    "    history : dict\n",
    "        Contains key 'loss' -> list of per-epoch full-dataset loss values.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9e323-ca2f-49a7-b312-b47115715d38",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9f5be9a2830f573f4343c0d6fa40840",
     "grade": true,
     "grade_id": "cell-1399346272ef4ba2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q4 Visble Tests (1 mark)\n",
    "_check_banned(train_logreg)\n",
    "seed=10\n",
    "X, y = gen_logreg(200, 300, 5, 1.3, seed)    \n",
    "w_tr, hist = train_logreg(X, y, lr=0.2, reg=1e-2, epochs=300)\n",
    "probs = 1/(1+np.exp(-(X@w_tr)))\n",
    "yhat = (probs >= 0.5).astype(int)\n",
    "acc = (yhat == y).mean()\n",
    "assert acc > 0.95\n",
    "print(\"Passed tests: +1 mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d1a33-c4ce-4f15-b5e3-7c52b6e1af1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edd4c0e93a5304f2434e6c9db0cf2b02",
     "grade": true,
     "grade_id": "cell-e29fc9eff391df2a",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q4 Hidden Tests (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7d8a6-5c3b-4c4c-8c82-39767c005636",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c793e2a4df16b51f0a724ed361ba1b4",
     "grade": true,
     "grade_id": "cell-375f66cc4583b835",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q4 Hidden Tests (6 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299bbdf-423c-45f1-9bca-1b5482b97019",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "183a7f613ec509ce9ff2350e660aa979",
     "grade": false,
     "grade_id": "cell-c20013e24748ba7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q5. Unsupervised Learning — K-means Clustering (10 marks)\n",
    "\n",
    "In this question you will implement functions to cluster polygon images into k clusters (k = number of shape types).\n",
    "\n",
    "Key constraints:\n",
    "- You must implement feature extraction from images that is robust to translation/scale/rotation/noise (e.g., normalized moments, eccentrity, compactness, edge density, radial profiles — your choice).\n",
    "- You must implement k-means.\n",
    "- Your solution should generalize to a hidden dataset (different seed, stronger noise/rotation ranges).\n",
    "- **Restriction (Q5): Do not import/call sklearn, tensorflow, keras, scikit-image, or any pre-built K-means functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e815559-6178-46e1-96b2-872fa35be12c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cc8b668411c60c44a868b751b665536",
     "grade": false,
     "grade_id": "cell-f6451621ee7966b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL - SETUP FOR REMAINING QUESTIONS\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Handy utilities\n",
    "def show_grid(images: np.ndarray, ncols=8, title=None):\n",
    "    \"\"\"\n",
    "    images: (N, H, W) or (N, 1, H, W) in 0..1 float\n",
    "    \"\"\"\n",
    "    imgs = images.copy()\n",
    "    if imgs.ndim == 4 and imgs.shape[1] == 1:\n",
    "        imgs = imgs[:, 0]\n",
    "    N, H, W = imgs.shape\n",
    "    ncols = min(ncols, N)\n",
    "    nrows = int(math.ceil(N / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(1.8*ncols, 1.8*nrows))\n",
    "    axes = np.array(axes).reshape(nrows, ncols)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < N:\n",
    "            ax.imshow(imgs[i], cmap=\"gray\", vmin=0, vmax=1)\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Image generator: polygons with translation, rotation, scale, thickness, and noise.\n",
    "def _regular_polygon_vertices(n_sides: int, radius: float, rotation: float) -> List[Tuple[float, float]]:\n",
    "    \"\"\"Generate vertices of a regular polygon centered at (0,0) before translation.\n",
    "    rotation in radians, radius in pixels.\"\"\"\n",
    "    return [\n",
    "        (\n",
    "            radius * math.cos(rotation + 2 * math.pi * k / n_sides),\n",
    "            radius * math.sin(rotation + 2 * math.pi * k / n_sides)\n",
    "        )\n",
    "        for k in range(n_sides)\n",
    "    ]\n",
    "\n",
    "def _transform_points(pts, tx: float, ty: float, scale: float) -> List[Tuple[float, float]]:\n",
    "    return [(scale * x + tx, scale * y + ty) for x, y in pts]\n",
    "\n",
    "def render_polygon_image(\n",
    "    n_sides: int,\n",
    "    img_size: int = 64,\n",
    "    radius: float = 20,\n",
    "    rotation_deg: float = 0,\n",
    "    translate: Tuple[float, float] = (0, 0),\n",
    "    scale: float = 1.0,\n",
    "    thickness: int = 1,\n",
    "    fill: bool = True,\n",
    "    blur: float = 0.0,\n",
    "    noise_std: float = 0.02,\n",
    "    antialias: int = 2,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns a single-channel grayscale image in [0,1] shape (1, H, W).\n",
    "    \"\"\"\n",
    "    H = W = img_size\n",
    "    big = img_size * antialias\n",
    "    img = Image.new(\"L\", (big, big), color=0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    rot = math.radians(rotation_deg)\n",
    "    base_pts = _regular_polygon_vertices(n_sides, radius * antialias, rot)\n",
    "    cx = cy = big // 2\n",
    "    tx, ty = translate\n",
    "    pts = _transform_points(base_pts, cx + tx * antialias, cy + ty * antialias, scale)\n",
    "\n",
    "    if fill:\n",
    "        draw.polygon(pts, fill=255)\n",
    "        if thickness > 0:\n",
    "            draw.line(pts + [pts[0]], fill=255, width=max(1, thickness * antialias))\n",
    "    else:\n",
    "        draw.line(pts + [pts[0]], fill=255, width=max(1, thickness * antialias))\n",
    "\n",
    "    if blur > 0:\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=blur * antialias))\n",
    "\n",
    "    # Downsample for antialiasing\n",
    "    if antialias > 1:\n",
    "        img = img.resize((W, H), resample=Image.Resampling.LANCZOS)\n",
    "\n",
    "    arr = np.asarray(img).astype(np.float32) / 255.0\n",
    "\n",
    "    if noise_std > 0:\n",
    "        arr = arr + np.random.normal(0, noise_std, size=arr.shape).astype(np.float32)\n",
    "\n",
    "    arr = np.clip(arr, 0.0, 1.0)\n",
    "    return arr[None, ...]  # (1,H,W)\n",
    "\n",
    "def sample_polygons_dataset(\n",
    "    n_per_class: int,\n",
    "    classes: List[int] = [3, 4, 5, 6],\n",
    "    img_size: int = 64,\n",
    "    noise_std: float = 0.03,\n",
    "    max_rotation_deg: float = 180,\n",
    "    max_translate: float = 8.0,\n",
    "    min_scale: float = 0.8,\n",
    "    max_scale: float = 1.2,\n",
    "    thickness: int = 1,\n",
    "    blur: float = 0.0,\n",
    "    antialias: int = 2,\n",
    "    rng: Optional[np.random.Generator] = None,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns X: (n,1,h,w) in [0,1], y: (n,) as class indices from [0..len(classes)-1].\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(123)\n",
    "    X_list, y_list = [], []\n",
    "    for ci, n_sides in enumerate(classes):\n",
    "        for _ in range(n_per_class):\n",
    "            rotation = float(rng.uniform(-max_rotation_deg, max_rotation_deg))\n",
    "            tx = float(rng.uniform(-max_translate, max_translate))\n",
    "            ty = float(rng.uniform(-max_translate, max_translate))\n",
    "            sc = float(rng.uniform(min_scale, max_scale))\n",
    "            radius = float(rng.uniform(16, 22))\n",
    "            img = render_polygon_image(\n",
    "                n_sides=n_sides,\n",
    "                img_size=img_size,\n",
    "                radius=radius,\n",
    "                rotation_deg=rotation,\n",
    "                translate=(tx, ty),\n",
    "                scale=sc,\n",
    "                thickness=thickness,\n",
    "                fill=True,\n",
    "                blur=blur,\n",
    "                noise_std=noise_std,\n",
    "                antialias=antialias,\n",
    "            )\n",
    "            X_list.append(img)\n",
    "            y_list.append(ci)\n",
    "    X = np.stack(X_list, axis=0).astype(np.float32)\n",
    "    y = np.array(y_list, dtype=np.int64)\n",
    "    idx = rng.permutation(len(y))\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "rng_demo = np.random.default_rng(42)\n",
    "X_demo, y_demo = sample_polygons_dataset(\n",
    "    n_per_class=8,\n",
    "    classes=[3,4,5,6],\n",
    "    img_size=64,\n",
    "    noise_std=0.03,\n",
    "    max_rotation_deg=180,\n",
    "    max_translate=8.0,\n",
    "    min_scale=0.8,\n",
    "    max_scale=1.2,\n",
    "    thickness=1,\n",
    "    blur=0.0,\n",
    "    antialias=2,\n",
    "    rng=rng_demo\n",
    ")\n",
    "print(\"Demo dataset:\", X_demo.shape, y_demo.shape)\n",
    "show_grid(X_demo[:32], ncols=8, title=\"Sample polygon images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a3b33-c928-4bfc-81c6-55236e71abb4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4e637380e2a8ebc58587c498570cd0a",
     "grade": false,
     "grade_id": "cell-80fbaf09fd4d8a46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL - SETUP FOR REMAINING QUESTIONS\n",
    "def silhouette_score(features: np.ndarray, labels: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute mean silhouette score without external libs.\n",
    "    \"\"\"\n",
    "    X = features.astype(np.float64, copy=False)\n",
    "    y = labels.astype(np.int64, copy=False)\n",
    "    N = X.shape[0]\n",
    "    # Precompute distances (O(N^2) but N is small in tests)\n",
    "    # Use squared Euclidean for efficiency; silhouette uses distances, but monotonic transformation preserves ordering.\n",
    "    # We will use true Euclidean distance for accuracy (still fast for small N).\n",
    "    dists = np.sqrt(((X[:, None, :] - X[None, :, :]) ** 2).sum(axis=2))\n",
    "    s_vals = []\n",
    "    for i in range(N):\n",
    "        same = (y == y[i])\n",
    "        other = ~same\n",
    "        same_idx = np.where(same)[0]\n",
    "        if len(same_idx) <= 1:\n",
    "            a = 0.0\n",
    "        else:\n",
    "            a = dists[i, same_idx][dists[i, same_idx] > 0].mean() if (dists[i, same_idx] > 0).any() else 0.0\n",
    "        # mean distance to each other cluster\n",
    "        other_clusters = np.unique(y[other])\n",
    "        if len(other_clusters) == 0:\n",
    "            b = 0.0\n",
    "        else:\n",
    "            means = []\n",
    "            for c in other_clusters:\n",
    "                idx = np.where(y == c)[0]\n",
    "                means.append(dists[i, idx].mean())\n",
    "            b = np.min(means) if len(means) > 0 else 0.0\n",
    "        denom = max(a, b)\n",
    "        s = 0.0 if denom == 0 else (b - a) / denom\n",
    "        s_vals.append(s)\n",
    "    return float(np.mean(s_vals)) if len(s_vals) > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7d1d1-a732-4259-82a0-8c2f1499cf2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3807f78e2357cccb6594c0bdec6b7e9",
     "grade": false,
     "grade_id": "cell-3ec220901f840e5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q5.1  Implement feature extraction (translation/scale/rotation/noise robustness) (4 marks)\n",
    "\n",
    "In this question, you will design a **classical vision** feature extractor for our polygon images (triangles, squares, pentagons). The goal is to produce **compact, informative, and robust** features that a simple classifier (provided elsewhere) can learn from, **without** using deep learning libraries.\n",
    "\n",
    "**Task**: implement extract_features(X) -> (n, d) float32 array.\n",
    "\n",
    "Input: X: (n, 1, h, w) with values in [0,1].\n",
    "\n",
    "Output: Return features that are reasonably invariant to translation/scale/rotation/noise.\n",
    "\n",
    "You may use numpy only (i.e., no scikit-image).\n",
    "\n",
    "Hints (you don't need all of these):\n",
    "- Normalized central moments up to 2nd order.\n",
    "- Eccentricity from covariance of foreground pixels.\n",
    "- Edge density (Sobel or simple finite differences).\n",
    "- Radial profile histogram from centroid.\n",
    "- Area and compactness: perimeter^2 / area (estimate perimeter via simple gradient)\n",
    "\n",
    "Your features MUST be deterministic and not rely on fixed seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc0058-d4a4-43bb-b267-68f23d8c7a89",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb0a0903ea6b9a3c2e4fe4d35341c793",
     "grade": false,
     "grade_id": "cell-d833e45248535683",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X: (n, 1, h, w) with values in [0,1].\n",
    "\n",
    "    Return features that are reasonably invariant to translation/scale/rotation/noise.\n",
    "    \n",
    "    Args:\n",
    "        X: (n, 1, h, w), float32 in [0,1]\n",
    "    Returns:\n",
    "        F: (n, ), float32\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b11c6-8964-4034-a029-d2f74ac7d158",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18afb0a03c85ad8ec8fbaad06d2f0d58",
     "grade": true,
     "grade_id": "cell-a1ddc128e4bb2ff4",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q5.1 Visible Tests (4 marks)\n",
    "_check_banned(extract_features)\n",
    "rng_vis = np.random.default_rng(2025)\n",
    "Xv, _ = sample_polygons_dataset(\n",
    "    n_per_class=6, classes=[3,4,5,6], img_size=64, noise_std=0.02,\n",
    "    max_rotation_deg=40, max_translate=4.0, min_scale=0.9, max_scale=1.1,\n",
    "    rng=rng_vis\n",
    ")\n",
    "Fv = extract_features(Xv)\n",
    "assert isinstance(Fv, np.ndarray), \"Features must be a numpy array\"\n",
    "assert Fv.ndim == 2 and Fv.shape[0] == Xv.shape[0], \"Feature shape must be (n, d)\"\n",
    "print(\"Passed tests: +4 marks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48883f-a547-4d9e-a3b5-b7fbb9d6a3d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19ebd741bdbbe53fb02be9bfabe72db4",
     "grade": false,
     "grade_id": "cell-063339a0c9512ef3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q5.2 Implement K-means (6 marks)\n",
    "\n",
    "Implement a simple k-means clustering using the notes from the lectures:\n",
    "- Inputs: features (n,d), k, max_iter, tol, rng (np.random.Generator)\n",
    "- Return: labels (n,) int in [0..k-1], and centers (k, d) with k clusters, each with d dimensions\n",
    "- Use k-means++ or random init. Must be deterministic given rng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04cdf6-e751-4a79-9753-07807977abc8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d253642dfa2b5f6ddb3268e6cf4680a0",
     "grade": false,
     "grade_id": "cell-0838354656af4c6f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def kmeans(features: np.ndarray, k: int, max_iter: int = 100, tol: float = 1e-4,\n",
    "           rng: Optional[np.random.Generator] = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        features: (n, d) array\n",
    "        k: number of clusters\n",
    "        max_iter: maximum k-means iterations\n",
    "        tol: convergence tolerance (max L2 shift of centres)\n",
    "        rng: np.random.Generator for determinism; if None, a default is used\n",
    "\n",
    "    Returns:\n",
    "        labels: (n,) cluster assignments in [0..k-1]\n",
    "        centers: (k, d) cluster centers\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfbf0c-70f3-410c-8e88-4aa6ab3f3588",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ebde62dc6f53353b731dc25d7d47bf2",
     "grade": true,
     "grade_id": "cell-4f6e4a7e81ea6f9d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q5.2 Visible Tests (1 mark)\n",
    "_check_banned(kmeans)\n",
    "rng_vis = np.random.default_rng(2025)\n",
    "Xv, _ = sample_polygons_dataset(\n",
    "    n_per_class=6, classes=[3,4,5,6], img_size=64, noise_std=0.02,\n",
    "    max_rotation_deg=40, max_translate=4.0, min_scale=0.9, max_scale=1.1,\n",
    "    rng=rng_vis)\n",
    "Fv = extract_features(Xv)\n",
    "labels_v, centers_v = kmeans(Fv, k=4, max_iter=50, rng=np.random.default_rng(0))\n",
    "assert labels_v.shape == (Xv.shape[0],), \"Labels must be (n,)\"\n",
    "assert len(np.unique(labels_v)) >= 3, \"K-means should produce multiple clusters\"\n",
    "print(\"Passed tests: +1 mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f6b18-f946-438a-80fe-8358ab54350d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba9e4ebaf3761b39843dad2ef0fc206c",
     "grade": true,
     "grade_id": "cell-d6205defc3410aaa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q5.2 Visible Tests (1 mark)\n",
    "_check_banned(kmeans)\n",
    "rng_vis = np.random.default_rng(2025)\n",
    "Xv, _ = sample_polygons_dataset(\n",
    "    n_per_class=6, classes=[3,4,5,6], img_size=64, noise_std=0.02,\n",
    "    max_rotation_deg=40, max_translate=4.0, min_scale=0.9, max_scale=1.1,\n",
    "    rng=rng_vis\n",
    ")\n",
    "Fv = extract_features(Xv)\n",
    "labels_v, centers_v = kmeans(Fv, k=4, max_iter=50, rng=np.random.default_rng(0))\n",
    "sv = silhouette_score(Fv, labels_v)\n",
    "assert np.isfinite(sv), \"Silhouette must be finite\"\n",
    "# Easy regime -> should be at least weakly positive\n",
    "assert sv > 0.05, f\"Silhouette too low in easy regime: {sv:.3f}\"\n",
    "print(\"Passed tests: +1 mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7eec7-212c-4268-87b6-27bf8e698c87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeeb91025e448d8b32a6f54bde09e593",
     "grade": true,
     "grade_id": "cell-3f66410e8d19381d",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q5 Hidden Tests (4 marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc70873-3987-40e5-930c-6ff1b8795659",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9226b1df620ce64b500cfe21f0af792",
     "grade": false,
     "grade_id": "cell-641ebc845fc1c48a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q6 Classification with a CNN (20 marks)\n",
    "\n",
    "Build and train a CNN to classify polygons into four classes: triangle, square, pentagon, hexagon.\n",
    "\n",
    "Constraints:\n",
    "- Train on synthetic images generated in-notebook (no external data).\n",
    "- Keep the model modest (< 150k parameters) and trainable on CPU in ~30–120 seconds.\n",
    "- Use a training/validation split derived from different seeds and augmentations.\n",
    "- Hidden tests will generate harder datasets (different seed, stronger noise, rotations, and scales).\n",
    "- You are allowed to use torch.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04ff15-1ecd-40f3-86d1-4094b9cc5be5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1082654409006d37c7a97d5cc103bbc2",
     "grade": false,
     "grade_id": "cell-12d268fb08cc99af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Reproducibility helper\n",
    "def set_all_seeds(seed: int = 123):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # torch.backends.cudnn.deterministic = True  # CPU-only for this assignment\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_all_seeds(7)\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "class PolygonsDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        assert X.ndim == 4 and X.shape[1] == 1\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]  # (1,H,W), float32\n",
    "        y = int(self.y[idx])\n",
    "        # Convert to torch tensors\n",
    "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "def make_split(\n",
    "    n_train_per_class=60,\n",
    "    n_val_per_class=20,\n",
    "    classes=[3,4,5,6],\n",
    "    img_size=64,\n",
    "    train_noise=0.04,\n",
    "    val_noise=0.05,\n",
    "    rng_train=np.random.default_rng(101),\n",
    "    rng_val=np.random.default_rng(202),\n",
    "):\n",
    "    Xtr, ytr = sample_polygons_dataset(\n",
    "        n_per_class=n_train_per_class, classes=classes, img_size=img_size,\n",
    "        noise_std=train_noise, max_rotation_deg=180, max_translate=10.0,\n",
    "        min_scale=0.75, max_scale=1.25, rng=rng_train\n",
    "    )\n",
    "    Xva, yva = sample_polygons_dataset(\n",
    "        n_per_class=n_val_per_class, classes=classes, img_size=img_size,\n",
    "        noise_std=val_noise, max_rotation_deg=180, max_translate=10.0,\n",
    "        min_scale=0.75, max_scale=1.25, rng=rng_val\n",
    "    )\n",
    "    return (Xtr, ytr), (Xva, yva)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba872c2-280b-4189-8dcc-deaf5bf2c398",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b2502c829d000de12414442b168789c",
     "grade": false,
     "grade_id": "cell-07e0ad1e3c46ec6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q6.1 Model definition (2 marks)\n",
    "\n",
    "**Build a CNN model with <150k parameters.**\n",
    "\n",
    "Tips:\n",
    "- Small conv stack + batch norm + dropout.\n",
    "- Global average pooling or small FC head.\n",
    "- Keep strides modest to preserve signal.\n",
    "- Input is (1, 64, 64).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f87635-c3a6-4348-92e6-70514cc804f7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b9ac0351557481d2b67112bbf12b50d",
     "grade": false,
     "grade_id": "cell-f7d0fa10dc543547",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class StudentNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A compact convolutional neural network for classifying simple 64×64 grayscale shapes.\n",
    "\n",
    "    **Intended use**\n",
    "    ----------------\n",
    "    - Input: tensors of shape **(n, 1, 64, 64)** with values in **[0, 1]** (float32).\n",
    "    - Output: **logits** of shape **(n, num_classes)**. Apply `softmax` externally if you need\n",
    "      probabilities, e.g., `F.softmax(logits, dim=1)`.\n",
    "\n",
    "    **Architecture**\n",
    "    ----------------\n",
    "    Feature extractor (`self.features`):\n",
    "      - **Blocks 1 to m (you decide on the number and shape of convolution blocks)\n",
    "\n",
    "    Head:\n",
    "      - Global Average Pooling to (n, k, 1, 1) → Flatten to (n, k)\n",
    "      - Dropout(p=0.20)\n",
    "      - Linear(k → num_classes)\n",
    "    \n",
    "    **Initialization**\n",
    "    ------------------\n",
    "    - Conv weights: Kaiming normal (fan_out, ReLU).\n",
    "    - BatchNorm: weight=1, bias=0.\n",
    "    - Linear: N(0, 0.01), bias=0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_classes : int, default=4\n",
    "        Number of output classes (size of the final linear layer).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 4):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input of shape **(n, 1, 64, 64)** with values in [0, 1], dtype float32.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            **Logits** of shape **(n, num_classes)**. Apply `softmax` externally if probabilities\n",
    "            are required; e.g., `F.softmax(logits, dim=1)`.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "def build_model(num_classes: int = 4) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Factory function to construct a `StudentNet`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_classes : int, default=4\n",
    "        Number of output classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nn.Module\n",
    "        An instance of `StudentNet(num_classes=num_classes)`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee20bb-d2e3-4b56-bf38-924f11de5785",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6387de5872db4e5327d6f63f3e2a4e1b",
     "grade": false,
     "grade_id": "cell-05a35a1a642d84d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q6.2 Training loop (18 marks)\n",
    "\n",
    "Implement a funtion to train the model, called train_model, with:\n",
    "- Adam or SGD optimizer\n",
    "- Cross-entropy loss\n",
    "- Reasonable Learning Rates and Number of Epochs (e.g., between 5 and 15)\n",
    "- Returns trained model and a history dict (loss/acc per epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7034c84-8af5-4292-898f-74447cbc688e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f812d16ac9fd4d225233a38c5e7d413f",
     "grade": false,
     "grade_id": "cell-fdc12fcc001d3559",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    epochs: int = 8,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 0.0,\n",
    "    device: torch.device = DEVICE,\n",
    ") -> Tuple[nn.Module, Dict[str, List[float]]]:\n",
    "    \"\"\"\n",
    "    Train a classification model for a fixed number of epochs using CrossEntropy loss and Adam,\n",
    "    and return the trained model together with per-epoch metrics.\n",
    "\n",
    "    This routine performs a standard supervised training loop:\n",
    "    - Moves the model to the specified `device`.\n",
    "    - For each epoch:\n",
    "      * **Training phase**: sets `model.train()`, iterates over `train_loader`, computes logits,\n",
    "        CrossEntropy loss, backpropagates, applies gradient clipping (max-norm=5.0), and steps the\n",
    "        Adam optimizer. Accumulates **training loss** and **accuracy**.\n",
    "      * **Validation phase**: sets `model.eval()`, disables grad, iterates over `val_loader`,\n",
    "        computes logits and CrossEntropy loss, and accumulates **validation loss** and **accuracy**.\n",
    "    - Records per-epoch metrics in a `history` dictionary:\n",
    "        `{'train_loss': [...], 'val_loss': [...], 'train_acc': [...], 'val_acc': [...]}`.\n",
    "\n",
    "    **Data/Model expectations**\n",
    "    - `train_loader` / `val_loader` must yield batches `(xb, yb)` where:\n",
    "        * `xb` is a float-like tensor of shape `(n, c, h, w)` (or `(n, d)` for MLPs) compatible with the model.\n",
    "        * `yb` is a `LongTensor` of shape `(n,)` with class indices in `[0, num_classes-1]`.\n",
    "    - The model’s `forward` must return **logits** of shape `(n, num_classes)` compatible with\n",
    "      `torch.nn.CrossEntropyLoss`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The neural network to train (moved to `device` at the start).\n",
    "    train_loader : DataLoader\n",
    "        Dataloader for training batches; must produce `(inputs, targets)`.\n",
    "    val_loader : DataLoader\n",
    "        Dataloader for validation batches; must produce `(inputs, targets)`.\n",
    "    epochs : int, default=8\n",
    "        Number of full passes over `train_loader`.\n",
    "    lr : float, default=1e-3\n",
    "        Learning rate for Adam.\n",
    "    weight_decay : float, default=0.0\n",
    "        L2 weight decay for Adam (applied to parameters via optimizer).\n",
    "    device : torch.device, default=DEVICE\n",
    "        Device on which to run training/validation (e.g., `torch.device('cuda')` or `'cpu'`).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : nn.Module\n",
    "        The trained model (still residing on `device`).\n",
    "    history : Dict[str, List[float]]\n",
    "        Per-epoch metrics:\n",
    "        - `history['train_loss']`: mean CrossEntropy on training set each epoch.\n",
    "        - `history['val_loss']`  : mean CrossEntropy on validation set each epoch.\n",
    "        - `history['train_acc']` : training accuracy each epoch in `[0,1]`.\n",
    "        - `history['val_acc']`   : validation accuracy each epoch in `[0,1]`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - **Criterion / Optimizer**: Uses `nn.CrossEntropyLoss()` and `torch.optim.Adam` with the provided\n",
    "      `lr` and `weight_decay`.\n",
    "    - **Gradient clipping**: Clips gradients by global norm at 5.0 to improve stability on noisy batches.\n",
    "    - **Dtypes & device**: Inputs are cast to `float` and moved to `device`; targets are moved as-is.\n",
    "    - **Determinism**: If you require reproducibility, set seeds and deterministic flags **outside**\n",
    "      this function (e.g., `torch.manual_seed`, `np.random.seed`, `torch.backends.cudnn.deterministic = True`).\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    >>> model = StudentNet(num_classes=4).to(device)\n",
    "    >>> model, history = train_model(model, train_loader, val_loader,\n",
    "    ...                              epochs=10, lr=1e-3, weight_decay=1e-4, device=device)\n",
    "    >>> history['val_acc'][-1]\n",
    "    0.92\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32042ff4-3e21-4275-a5c0-cee1d8a89b61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaa333526789851550bf131f13f5785a",
     "grade": true,
     "grade_id": "cell-33b6a37096b12d0d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q6 Visible Tests (1 mark)\n",
    "\n",
    "set_all_seeds(10)\n",
    "(Xtr, ytr), (Xva, yva) = make_split(\n",
    "    n_train_per_class=40, n_val_per_class=12, img_size=64,\n",
    "    train_noise=0.03, val_noise=0.04,\n",
    "    rng_train=np.random.default_rng(333),\n",
    "    rng_val=np.random.default_rng(444)\n",
    ")\n",
    "train_ds = PolygonsDataset(Xtr, ytr)\n",
    "val_ds = PolygonsDataset(Xva, yva)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "model = build_model(num_classes=4).to(DEVICE)\n",
    "\n",
    "# Param budget\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "assert n_params < 150_000, f\"Model too large: {n_params} parameters\"\n",
    "print(\"Passed tests: +1 mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a976aa2f-3022-4123-a7cb-fa7bf866e4f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01e26c48d5b3d46a50f29d3428c07d75",
     "grade": true,
     "grade_id": "cell-faf4f11c1f3533a0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q6 Visible Tests (1 mark)\n",
    "\n",
    "set_all_seeds(10)\n",
    "(Xtr, ytr), (Xva, yva) = make_split(\n",
    "    n_train_per_class=40, n_val_per_class=12, img_size=64,\n",
    "    train_noise=0.03, val_noise=0.04,\n",
    "    rng_train=np.random.default_rng(333),\n",
    "    rng_val=np.random.default_rng(444)\n",
    ")\n",
    "train_ds = PolygonsDataset(Xtr, ytr)\n",
    "val_ds = PolygonsDataset(Xva, yva)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "model = build_model(num_classes=4).to(DEVICE)\n",
    "\n",
    "# Forward shape check\n",
    "xb, yb = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    logits = model(xb.to(DEVICE).float())\n",
    "assert logits.shape == (xb.shape[0], 4), f\"Logits shape incorrect: {logits.shape}\"\n",
    "print(\"Passed tests: +1 mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b4c7d-078d-4364-b65e-c22f2c0a8d5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2da2d2cc6ad9b103d26f7c838b8b8da5",
     "grade": true,
     "grade_id": "cell-f4cdea92867dedaf",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q6 Visible Tests (2 marks)\n",
    "\n",
    "set_all_seeds(10)\n",
    "(Xtr, ytr), (Xva, yva) = make_split(\n",
    "    n_train_per_class=40, n_val_per_class=12, img_size=64,\n",
    "    train_noise=0.03, val_noise=0.04,\n",
    "    rng_train=np.random.default_rng(333),\n",
    "    rng_val=np.random.default_rng(444)\n",
    ")\n",
    "train_ds = PolygonsDataset(Xtr, ytr)\n",
    "val_ds = PolygonsDataset(Xva, yva)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "model = build_model(num_classes=4).to(DEVICE)\n",
    "\n",
    "# Quick training: small epochs, should beat chance significantly (> 0.5 on easy val)\n",
    "model, hist = train_model(model, train_loader, val_loader, epochs=4, lr=1e-3, weight_decay=0.0, device=DEVICE)\n",
    "assert \"val_acc\" in hist and len(hist[\"val_acc\"]) >= 1\n",
    "acc_last = hist[\"val_acc\"][-1]\n",
    "assert acc_last >= 0.3, f\"Validation accuracy too low on visible split: {acc_last:.3f}\"\n",
    "print(\"Passed tests: +2 marks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d240d-f461-4d3e-992a-483fb3edfb35",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7617b29c26a73783ab23921dfd89036f",
     "grade": true,
     "grade_id": "cell-68034f254b432c8a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q6 Hidden Tests (5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d3186-9661-486d-abde-3bce3645b0ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fb936d7670c54066ceb2a39ea0feac0",
     "grade": true,
     "grade_id": "cell-9d040b823235483a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q6 Hidden Tests (5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f536032-5943-4db0-a1ff-88daac595f97",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cda68ac300aa3f11fa1597a0ee2424d",
     "grade": true,
     "grade_id": "cell-5b86479d542e380b",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Q6 Hidden Tests (6 marks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
